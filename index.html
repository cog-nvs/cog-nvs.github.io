<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Reconstruct, Inpaint, Finetune: Dynamic Novel-view Synthesis from Monocular Videos">
  <meta name="keywords" content="novel-view synthesis, 4D reconstruction, video diffusion, diffusion inpainting">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Reconstruct, Inpaint, Finetune: Dynamic Novel-view Synthesis from Monocular Videos</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/cognvsicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>


  <style>
.card-img {
    width: 120px;
    height: auto;
    border-radius: 8px;
    box-shadow: 0 4px 10px rgba(0, 0, 0, 0.1);
    transition: transform 0.2s;
    cursor: pointer;
}

.card-img:hover {
    transform: scale(1.05);
}
</style>

</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Reconstruct, Inpaint, Finetune:<br>Dynamic Novel-view Synthesis from Monocular Videos</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://github.com/Kaihua-Chen/">Kaihua Chen</a><sup>*</sup>,&nbsp;</span>
            <span class="author-block">
              <a href="https://www.cs.cmu.edu/~tkhurana/">Tarasha Khurana</a><sup>*</sup>,&nbsp;</span>
            <span class="author-block">
              <a href="https://www.cs.cmu.edu/~deva/">Deva Ramanan</a>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block">Carnegie Mellon University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2507.12646"
                   class="external-link button is-normal is-rounded is-dark"
                   >
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2507.12646"
                   class="external-link button is-normal is-rounded is-dark"
                   >
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/Kaihua-Chen/cog-nvs"
                   class="external-link button is-normal is-rounded is-dark"
                   >
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (coming soon)</span>
                  </a>
              </span>
          </div>
        </div>
      </div>
    </div>
  </div>

</section>


<section class="section" style="margin-top: -5rem;">
  <div class="container is-max-desktop has-text-centered">
    <p class="is-size-5 has-text-weight-semibold">
      TL;DR: CogNVS is a video diffusion model for dynamic novel-view synthesis trained in a self-supervised manner using only 2D videos!
       We reformulate novel-view synthesis as a structured inpainting task: (1) we reconstruct input views with off-the-shelf SLAM systems,
        (2) create self-supervised training pairs for pretraining an inpainting model, and (3) test-time finetune to the input at inference.
    </p>
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <!-- <h2 class="subtitle">
        We present CogNVS, a video diffusion model for novel-view synthesis of dynamic scenes. 
        Given an in-the-wild monocular video capturing a dynamic scene, we first reconstruct the scene, render it from the target novel-view and inpaint any unobserved regions. 
        Because CogNVS can be pre-trained via self-supervision, it can also be test-time-finetuned on a given target video, enabling it to zero-shot generalize to novel domains.
        Here, we illustrate CogNVS’s “reconstruct, inpaint, finetune” pipeline on a sample video.
      </h2> -->

      <p>Given an in-the-wild monocular video capturing a dynamic scene, we first reconstruct the scene, render it from the target novel-view and inpaint any unobserved regions. 
        Because CogNVS can be pre-trained via self-supervision, it can also be test-time-finetuned on a given target video, enabling it to zero-shot generalize to novel domains.
        Here, we illustrate CogNVS’s “reconstruct, inpaint, finetune” pipeline on a sample video.</p>
    </div>
  </div>
</section>

<div class="columns is-centered has-text-centered">
<h2 class="title is-3">In-the-wild Real-world Gallery</h2>
</div>

<section class="hero is-light is-small">

  <div class="hero-body">

      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-bear">
          <video poster="" id="bear" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/exp01_davis_bear_concat.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-hike">
          <video poster="" id="hike" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/exp02_davis_hike_concat.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-robot_manip">
          <video poster="" id="robot_manip" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/exp03_robot_manip_concat.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-robot_humanoid">
          <video poster="" id="robot_humanoid" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/exp04_robot_humanoid_concat.mp4"
                    type="video/mp4">
          </video>
        </div>
        
        <div class="item item-mv_superman">
          <video poster="" id="mv_superman" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/exp05_mv_superman_concat.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-mv_friends">
          <video poster="" id="mv_friends" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/exp06_mv_friends_concat.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-davis_blackswan">
          <video poster="" id="davis_blackswan" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/exp07_davis_blackswan_concat.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-static_outdoor">
          <video poster="" id="static_outdoor" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/exp10_static_outdoor_concat.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-static_room">
          <video poster="" id="static_room" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/exp11_static_room_concat.mp4"
                    type="video/mp4">
          </video>
        </div>
      
      </div>

      <div class="container">
      <div class="columns is-mobile has-text-centered mb-0 mt-0 is-size-6">
      <div class="column">(a) Input video</div>
      <div class="column">(b) Novel-view renders</div>
      <div class="column">(c) Novel-view by CogNVS</div>
    </div>
    </div>
  </div>
</section>



<section class="section"> 
<div class="columns is-centered has-text-centered">
<h2 class="title is-3">In-the-wild Synthetic Gallery</h2>
</div>

<section class="hero is-light is-small">

  <div class="hero-body">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-sora_monster">
          <video poster="" id="sora_monster" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/exp12_sora_monster_concat.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-sora_balloon">
          <video poster="" id="sora_balloon" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/exp13_sora_balloon_concat.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-sora_mammoth">
          <video poster="" id="sora_mammoth" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/exp14_sora_mammoth_concat.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-sora_corgi">
          <video poster="" id="sora_corgi" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/exp15_sora_corgi_concat.mp4"
                    type="video/mp4">
          </video>
        </div>
        
        <div class="item item-sora_kangroo">
          <video poster="" id="sora_kangroo" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/exp16_sora_kangroo_concat.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-sora_grandmom">
          <video poster="" id="sora_grandmom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/exp17_sora_grandmom_concat.mp4"
                    type="video/mp4">
          </video>
        </div>
      
      </div>

      <div class="container">
      <div class="columns is-mobile has-text-centered mb-0 mt-0 is-size-6">
      <div class="column">(a) Input video</div>
      <div class="column">(b) Novel-view renders</div>
      <div class="column">(c) Novel-view by CogNVS</div>
      </div>

      
    </div>
  </div>
</section>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            We explore novel-view synthesis for dynamic scenes from monocular videos. Prior approaches rely on costly test-time optimization of 4D representations or do not preserve scene geometry when trained in a feed-forward manner. 
            Our approach is based on three key insights: (1) <em>covisible</em> pixels (that are visible in both the input and target views) can be rendered by first reconstructing the dynamic 3D scene and rendering the reconstruction from the novel-views and 
            (2) <em>hidden</em> pixels in novel views can be "inpainted" with feed-forward 2D video diffusion models. Notably, our video inpainting diffusion model (CogNVS) can be self-supervised from 2D videos, allowing us to train it on a large corpus of in-the-wild videos. 
            This in turn allows for (3) CogNVS to be applied zero-shot to novel test videos via <em>test-time finetuning</em>. 
            We empirically verify that CogNVS outperforms almost all prior art for novel-view synthesis of dynamic scenes from monocular videos.
          </p>
          
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>



<section class="section">



  <div class="container is-max-desktop"  style="margin-bottom: 80px;">

    <div class="columns is-centered">

      <!-- Comparison on Kubric. -->
      <div id="kubric-compare" class="row method-block" style="display: block;">
        <h2 class="title is-3">Comparison on Kubric-4D</h2>

         <p class="mb-4">
            We evaluate CogNVS on the synthetic Kubric-4D dataset. Under extreme novel-view conditions, 
            our method preserves sharp object boundaries and maintains 3D-consistent geometry of dynamic scenes, 
            while successfully revealing occluded objects and background regions.
          </p>

        <div class="col-md-6 offset-md-2">

          <table width=960px style="text-align: center; margin-bottom: -5px;">
            <tr>
                <td width=200px>Input view</td>
                <td width=200px>GT point cloud</td>
                <td width=200px>GCD</td>
                <td width=200px>TrajCrafter</td>
                <td width=200px>CogNVS</td>
                <td width=200px>GT novel view</td>
            </tr>
            <tr>
              <td colspan="6">
                <video id="kubric-video" class="video" width="100%" loop playsinline autoplay muted controls>
                  <source src="./static/videos/kubric/kubric2912.mp4" type="video/mp4">
                </video>
              </td>
            </tr>
          </table>
          <br>
        </div>

        <!-- thumbnails row -->
        <div class="columns is-mobile is-justify-content-center" id="kubric-pills">
          <div class="column is-narrow kubric-pill" data-value="kubric2910">
            <figure class="image is-96x96">
              <img class="card-img" src="./static/videos/kubric/kubric2910.png" alt="kubric2910">
            </figure>
          </div>
          <div class="column is-narrow kubric-pill" data-value="kubric2915">
            <figure class="image is-96x96">
              <img class="card-img" src="./static/videos/kubric/kubric2915.png" alt="Spin">
            </figure>
          </div>
          <div class="column is-narrow kubric-pill" data-value="kubric2912">
            <figure class="image is-96x96">
              <img class="card-img" src="./static/videos/kubric/kubric2912.png" alt="kubric">
            </figure>
          </div>
          <div class="column is-narrow kubric-pill" data-value="kubric2917">
            <figure class="image is-96x96">
              <img class="card-img" src="./static/videos/kubric/kubric2917.png" alt="Teddy">
            </figure>
          </div>

          <div class="column is-narrow kubric-pill" data-value="kubric2918">
            <figure class="image is-96x96">
              <img class="card-img" src="./static/videos/kubric/kubric2918.png" alt="Teddy">
            </figure>
          </div>
        </div>
      </div>

    </div>
  </div>


  <div class="container is-max-desktop"  style="margin-bottom: 80px;">

    <div class="columns is-centered">

      <!-- Comparison on Pardom. -->
      <div id="pardom-compare" class="row method-block" style="display: block;">
        <h2 class="title is-3">Comparison on ParallelDomain-4D</h2>

         <p class="mb-4">
            On the synthetic ParallelDomain-4D dataset featuring autonomous driving scenarios, 
            CogNVS effectively hallucinates plausible road layouts and vehicle motions in novel views.
          </p>

        <div class="col-md-6 offset-md-2">

          <table width=960px style="text-align: center; margin-bottom: -5px;">
            <tr>
                <td width=200px>Input view</td>
                <td width=200px>GT point cloud</td>
                <td width=200px>GCD</td>
                <td width=200px>TrajCrafter</td>
                <td width=200px>CogNVS</td>
                <td width=200px>GT novel view</td>
            </tr>
            <tr>
              <td colspan="6">
                <video id="pardom-video" class="video" width="100%" loop playsinline autoplay muted controls>
                  <source src="./static/videos/pardom/pardom173.mp4" type="video/mp4">
                </video>
              </td>
            </tr>
          </table>
          <br>
        </div>

        <!-- thumbnails row -->
        <div class="columns is-mobile is-justify-content-center" id="pardom-pills">
          <div class="column is-narrow pardom-pill" data-value="pardom48">
            <figure class="image is-96x96">
              <img class="card-img" src="./static/videos/pardom/pardom48.png" alt="pardom48">
            </figure>
          </div>
          <div class="column is-narrow pardom-pill" data-value="pardom167">
            <figure class="image is-96x96">
              <img class="card-img" src="./static/videos/pardom/pardom167.png" alt="pardom167">
            </figure>
          </div>
          <div class="column is-narrow pardom-pill" data-value="pardom173">
            <figure class="image is-96x96">
              <img class="card-img" src="./static/videos/pardom/pardom173.png" alt="pardom173">
            </figure>
          </div>
          <div class="column is-narrow pardom-pill" data-value="pardom181">
            <figure class="image is-96x96">
              <img class="card-img" src="./static/videos/pardom/pardom181.png" alt="pardom181">
            </figure>
          </div>

          <div class="column is-narrow pardom-pill" data-value="pardom294">
            <figure class="image is-96x96">
              <img class="card-img" src="./static/videos/pardom/pardom294.png" alt="pardom294">
            </figure>
          </div>
        </div>
      </div>

    </div>
  </div>

  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Comparison on DyCheck. -->


      <div id="dycheck-compare" class="row method-block" style="display: block;">
        <h2 class="title is-3">Comparison on DyCheck</h2>

         <p class="mb-4">
            We also benchmark CogNVS on the real-world DyCheck dataset. Here, 
            CogNVS<sup>1</sup> leverages renders from MegaSAM, and CogNVS<sup>2</sup> from Mosca. 
            Despite starting from noisy and incomplete point cloud renders (e.g., from MegaSAM),
             our approach still generates photo-realistic and 3D-consistent novel views.
          </p>

        <div class="col-md-8 offset-md-2">

          <table width=960px style="text-align: center; margin-bottom: -5px;">
            <tr>
              <td width="200px">Input view</td>
              <td width="200px">MegaSAM</td>
              <td width="200px">Shape‑of‑Motion</td>
              <td width="200px">Mosca</td>
              <td width="200px">CAT4D</td>
              <td width="200px">TrajCrafter</td>
              <td width="200px">CogNVS<sup>1</sup></td>
              <td width="200px">CogNVS<sup>2</sup></td>
            </tr>
            <tr>
              <td colspan="8">
                <video id="dycheck-video" class="video" width="100%" loop playsinline autoplay muted controls>
                  <source src="./static/videos/dycheck/paper-windmill.mp4" type="video/mp4">
                </video>
              </td>
            </tr>
          </table>
          <br>
        </div>

        <!-- thumbnails row -->
        <div class="columns is-mobile is-justify-content-center" id="dycheck-pills">
          <div class="column is-narrow scene-pill" data-value="apple">
            <figure class="image is-96x96">
              <img class="card-img" src="./static/videos/dycheck/apple.png" alt="Apple">
            </figure>
          </div>
          <div class="column is-narrow scene-pill" data-value="block">
            <figure class="image is-96x96">
              <img class="card-img" src="./static/videos/dycheck/block.png" alt="Block">
            </figure>
          </div>
          <div class="column is-narrow scene-pill" data-value="paper-windmill">
            <figure class="image is-96x96">
              <img class="card-img" src="./static/videos/dycheck/paper-windmill.png" alt="Paper Windmill">
            </figure>
          </div>
          <div class="column is-narrow scene-pill" data-value="spin">
            <figure class="image is-96x96">
              <img class="card-img" src="./static/videos/dycheck/spin.png" alt="Spin">
            </figure>
          </div>
          <div class="column is-narrow scene-pill" data-value="teddy">
            <figure class="image is-96x96">
              <img class="card-img" src="./static/videos/dycheck/teddy.png" alt="Teddy">
            </figure>
          </div>
        </div>
      </div>

    </div>
  </div>

</section>



<section class="section">


  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column">
        <div class="content">
          <h2 class="title is-3">How does it work?</h2>
          <p>
            <!-- <strong>CogNVS Overview.</strong> -->
            During training (<strong>left</strong>), given a 2D source video (in <span style="color:blue;">blue</span>) of a dynamic scene, we first reconstruct the scene using off-the-shelf monocular reconstruction algorithms like MegaSAM to obtain the 3D scene geometry, 
            \( \mathcal{G}_{\rm src} \), and camera odometry, \( \mathbf{c}_{\rm src} \). We then sample a set of arbitrary camera trajectories \( \{\mathbf{c}_1, \cdots, \mathbf{c}_N\} \) to simulate plausible occluded geometries, 
            \( \{\mathcal{G}^{\rm cov}_{{\rm src},1}, \cdots, \mathcal{G}^{\rm cov}_{{\rm src},N}\} \), which when rendered from original camera trajectory \( \mathbf{c}_{\rm src} \) produces a mask of source pixels that are co-visible in the sampled trajectory (in <span style="color:orange;">orange</span>). 
            The source video and its masked variant produce a self-supervised training pair for learning CogNVS, our video inpainting diffusion model (visualized in the next figure).
            At inference (<strong>right</strong>), we finetune CogNVS on the given input sequence by similarly constructing self-supervised training pairs. The final novel-view is then generated using the finetuned CogNVS in a feed-forward manner.
          </p>
          <img src="./static/images/method.png" alt="Method Figure" width="100%">
          
          <!-- &nbsp;
          &nbsp;
          <p>
            <strong>Self-supervised training data generation.</strong> To curate a large training set for video inpainting, we first reconstruct an input source 2D video (in <span style="color:blue;">blue</span>) with an off-the-shelf monocular SLAM system. After reconstruction, we randomly sample \( N \) pairs of ‘start’ and ‘end’ camera poses around a spherical region, \( \mathcal{S} \), of the estimated camera pose in the given 2D video. \( \mathcal{S} \) is bounded by a predefined deviation in the spherical coordinate axes.
            We sample an \( \mathrm{SE(3)} \) camera trajectory that interpolates the start and end poses while looking at the center of the scene. We render the reconstruction from this novel trajectory (in <span style="color:orange;"><em>dotted-orange</em></span>), and use the rendering to identify co-visible pixels in the original source view (in <span style="color:orange;">orange</span>). The source video and its masked variant are used to produce a self-supervised training pair for training CogNVS, our “3D-aware” video inpainting diffusion.
          </p>
          <img src="./static/images/data_gen.png" alt="Data Generation Figure" width="100%"> -->
        </div>
      </div>
    </div>

  </div>

</section>


    <!--/ Pseudo-gt. -->


    <!-- Concurrent Work. -->

    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          Coming soon!
        </div>
      </div>
    </div> -->

    <!--/ Concurrent Work. -->



<section class="section" id="BibTeX">
  <div class="container is-max-desktop content" style="margin-bottom: 30px;">
    <h2 class="title">
      BibTeX
    </h2>
    <pre><code id="bibtex-code">@article{chen2025cognvs,
  title={Reconstruct, Inpaint, Finetune: Dynamic Novel-view Synthesis from Monocular Videos},
  author={Kaihua Chen and Tarasha Khurana and Deva Ramanan},
  year={2025},
  archivePrefix={arXiv},
  eprint={2507.12646},
  primaryClass={cs.CV},
  url={https://arxiv.org/abs/2507.12646}
}</code></pre>
<button id="copy-bibtex-btn"
              class="button is-light is-pulled-left"
              type="button"
              aria-label="Copy BibTeX to clipboard">
        Copy
      </button>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <!-- <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/Kaihua-Chen" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content" style="text-align: center;">
          <p>
            This website is borrowed from <a
              href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. We sincerely thank them for this excellent open-source template!
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>


<script>
  document.addEventListener('DOMContentLoaded', () => {
    document.querySelectorAll('#dycheck-pills .scene-pill').forEach(pill => {
      pill.addEventListener('click', () => {
        const scene = pill.dataset.value;
        const video = document.getElementById('dycheck-video');
        const source = video.querySelector('source');
        source.src = `./static/videos/dycheck/${scene}.mp4`;
        video.load();
      });
    });

    document.querySelectorAll('#kubric-pills .kubric-pill').forEach(pill => {
    pill.addEventListener('click', () => {
      const scene = pill.dataset.value;
      const video = document.getElementById('kubric-video');
      video.querySelector('source').src = `./static/videos/kubric/${scene}.mp4`;
      video.load();
    });
  });

  document.querySelectorAll('#pardom-pills .pardom-pill').forEach(pill => {
    pill.addEventListener('click', () => {
      const scene = pill.dataset.value;
      const video = document.getElementById('pardom-video');
      video.querySelector('source').src = `./static/videos/pardom/${scene}.mp4`;
      video.load();
    });
  });
  });


  document.addEventListener('DOMContentLoaded', function () {
  const btn  = document.getElementById('copy-bibtex-btn');
  const code = document.getElementById('bibtex-code');
  if (!btn || !code) return;

  btn.addEventListener('click', async () => {
    const text = code.innerText.trim();
    async function copyFallback() {
      const ta = document.createElement('textarea');
      ta.value = text;
      ta.style.position = 'fixed';
      ta.style.top = '-1000px';
      document.body.appendChild(ta);
      ta.focus();
      ta.select();
      try { document.execCommand('copy'); } catch (_) {}
      document.body.removeChild(ta);
    }
    try {
      await navigator.clipboard.writeText(text);
    } catch (err) {
      await copyFallback();
    }
    const old = btn.textContent;
    btn.textContent = 'Copied!';
    setTimeout(() => { btn.textContent = old; }, 1500);
  });
});
  
</script>

</body>
</html>
